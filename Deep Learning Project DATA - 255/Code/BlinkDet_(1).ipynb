{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mvvzld-GFMH"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils.video import FileVideoStream\n",
        "from imutils.video import VideoStream\n",
        "from imutils import face_utils\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2 \n",
        "import datetime\n",
        "import csv\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7fWv7Ov0Lnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6237c292-05e6-4797-9b15-50bf607bef25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive #using google drive for storage\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCLxOHtKHAfD"
      },
      "outputs": [],
      "source": [
        "#declaring variables\n",
        "blink_duration = []\t\n",
        "start_timestamp = [] \n",
        "timestamp = []  \n",
        "avgBlinkDurationBuffer = []\n",
        "avgBlinkFreqBuffer = []\n",
        "operclos = []\n",
        "average_perclos = []\n",
        "eyelid_timestamp = []\n",
        "eyelid_open_timestamp = []\n",
        "closing_eye_movement = []\n",
        "opening_eye_movement = []\n",
        "headPose1 = []\n",
        "kss_val = []\n",
        "yawning = []\n",
        "mar = []\n",
        "\n",
        "sDir = \"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY\"\n",
        "EYE_AR_THRESH = 0.3\n",
        "MOUTH_AR_THRESH = 0.79"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epFS2BmaHAiC"
      },
      "outputs": [],
      "source": [
        "# grab the indexes of the facial landmarks for the left and\n",
        "# right eye, respectively\n",
        "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "\n",
        "\t\n",
        "def eye_aspect_ratio(eye):\n",
        "  # compute the euclidean distances between the two sets of\n",
        "  # vertical eye landmarks (x, y)-coordinates\n",
        "\n",
        "  A = dist.euclidean(eye[1], eye[5])\n",
        "  B = dist.euclidean(eye[2], eye[4])\n",
        " \n",
        "  # compute the euclidean distance between the horizontal\n",
        "  # eye landmark (x, y)-coordinates\n",
        "  C = dist.euclidean(eye[0], eye[3])\n",
        " \n",
        "  # compute the eye aspect ratio\n",
        "  ear = (A + B) / (2.0 * C)\n",
        "\n",
        "  # return the eye aspect ratio\n",
        "  return ear"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance as dist\n",
        "\n",
        "(omouth, emouth) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
        "def mouth_aspect_ratio(mouth):\n",
        "    # compute the euclidean distances between the two sets of\n",
        "    # vertical mouth landmarks (x, y)-coordinates\n",
        "    A = dist.euclidean(mouth[2], mouth[10])  # 51, 59\n",
        "    B = dist.euclidean(mouth[4], mouth[8])  # 53, 57\n",
        "\n",
        "    # compute the euclidean distance between the horizontal\n",
        "    # mouth landmark (x, y)-coordinates\n",
        "    C = dist.euclidean(mouth[0], mouth[6])  # 49, 55\n",
        "\n",
        "    # compute the mouth aspect ratio\n",
        "    mar = (A + B) / (2.0 * C)\n",
        "\n",
        "    # return the mouth aspect ratio\n",
        "    return mar"
      ],
      "metadata": {
        "id": "a5wz_Xi6kABd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_points = np.array([\n",
        "    (359, 391),     # Nose tip 34\n",
        "    (399, 561),     # Chin 9\n",
        "    (337, 297),     # Left eye left corner 37\n",
        "    (513, 301),     # Right eye right corne 46\n",
        "    (345, 465),     # Left Mouth corner 49\n",
        "    (453, 469)      # Right mouth corner 55\n",
        "], dtype=\"double\")"
      ],
      "metadata": {
        "id": "U6FbvodGm1Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHvL6gweHAl6"
      },
      "outputs": [],
      "source": [
        "def init():\n",
        "\n",
        "\t#timestamp = [] \n",
        "\tsAnnotateFile = sDir + '/annotations-auto/1-1-s2.txt'\n",
        "\t#opening the annotations file\n",
        "\twith open(sAnnotateFile, 'r') as f:\n",
        "\t     data = f.readlines()\n",
        "\t\n",
        "\t\n",
        "\t#opening timestamps file\n",
        "\twith open('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/timestamps/1-1.txt', 'r') as f1:\n",
        "\t\ttime = f1.readlines()\n",
        "\n",
        "\t#opening head pose file\n",
        "\t#with open('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/headPoseValues/9-3_hp.txt', 'r') as f2:\n",
        "\t\t#headpos = f2.readlines()\n",
        "\n",
        "\t#opening kss file\n",
        "\twith open('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/kss/1-1.txt','r') as f3:\n",
        "\t\tkss = f3.readlines()\n",
        "\n",
        "\t\n",
        "\tFeatureExtracionDict = {'time': time, 'start_timestamp': start_timestamp, 'avgBlinkDurationBuffer': avgBlinkDurationBuffer, 'avgBlinkFreqBuffer': avgBlinkFreqBuffer, 'timestampEveryMin': timestamp, 'blink_duration': blink_duration, 'perclos': operclos, 'TimeEveryMin_eye': eyelid_timestamp, 'closingEyedur': closing_eye_movement, 'openingEyedur': opening_eye_movement, 'TimeEveryMinEyeOpen': eyelid_open_timestamp, 'average_perclos': average_perclos, 'kss': kss, 'kss_val': kss_val, \"headpos1\": headPose1, \"MAR\": mar, \"Yawning\": yawning}\n",
        "\treturn FeatureExtracionDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_DcQ0H4HApW"
      },
      "outputs": [],
      "source": [
        "#finding the time difference\n",
        "def time_difference(start_time, end_time):\n",
        "\tstart_time = start_time.split()\t\n",
        "\tfor i in range(0,8):\n",
        "\t\thours = int(start_time[3])\n",
        "\t\tmins = int(start_time[4])\n",
        "\t\tsecs = int(start_time[5])\n",
        "\t\tmilisecs = int(start_time[6])\n",
        "\t\tmicrosecs = int(start_time[7])\n",
        "\t#converting it to microsecs\n",
        "\tt1, m1, s1, ms1, mis1  = hours, mins, secs, milisecs, microsecs\n",
        "\tstart_time_microsecs = mis1 + 1000*(ms1 + 1000*(s1 + 60*(m1 + 60*t1)))\n",
        "\t\n",
        "\n",
        "\tend_time = end_time.split()\n",
        "\tfor x in range(0,8,1):\n",
        "\t\thours = int(end_time[3])\n",
        "\t\tmins = int(end_time[4])\n",
        "\t\tsecs = int(end_time[5])\n",
        "\t\tmilisecs = int(end_time[6])\n",
        "\t\tmicrosecs = int(end_time[7])\t\n",
        "\t\n",
        "\tt2, m2, s2, ms2, mis2  = hours, mins, secs, milisecs, microsecs\n",
        "\tend_time_microsecs = mis2 + 1000*(ms2 + 1000*(s2 + 60*(m2 + 60*t2)))\n",
        "\t#finding the duration of blink\n",
        "\ttime_differ = end_time_microsecs - start_time_microsecs\n",
        "\t#print 'time_difference in microsecs = ', time_differ\n",
        "\treturn time_differ\n",
        "\n",
        "\n",
        "\n",
        "#for clearing the buffer after every minute\n",
        "def one_min(current_time, buffer1):\n",
        "\twhile(len(current_time) > 0):\n",
        "\t\t\n",
        "\t\t\n",
        "\t\tostart = current_time[0]\n",
        "\t\toend = current_time[-1]\n",
        "\t\tdiff = time_difference(ostart, oend)\n",
        "\t\tif diff > 6e+7:\n",
        "\t\t\tdel current_time[0]\n",
        "\t\t\tdel buffer1[0]\n",
        "\t\telse:\n",
        "\t\t\tbreak\n",
        "\treturn current_time, buffer1\t\n",
        "\t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/shape_predictor_68_face_landmarks.dat')"
      ],
      "metadata": {
        "id": "fg-3xYcNzuRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_width = 1024\n",
        "frame_height = 576"
      ],
      "metadata": {
        "id": "RSr_cmLU3Jjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),             # Nose tip 34\n",
        "    (0.0, -330.0, -65.0),        # Chin 9\n",
        "    (-225.0, 170.0, -135.0),     # Left eye left corner 37\n",
        "    (225.0, 170.0, -135.0),      # Right eye right corne 46\n",
        "    (-150.0, -150.0, -125.0),    # Left Mouth corner 49\n",
        "    (150.0, -150.0, -125.0)      # Right mouth corner 55\n",
        "])\n",
        "def isRotationMatrix(R):\n",
        "    Rt = np.transpose(R)\n",
        "    shouldBeIdentity = np.dot(Rt, R)\n",
        "    I = np.identity(3, dtype=R.dtype)\n",
        "    n = np.linalg.norm(I - shouldBeIdentity)\n",
        "    return n < 1e-6\n",
        "\n",
        "\n",
        "# Calculates rotation matrix to euler angles\n",
        "# The result is the same as MATLAB except the order\n",
        "# of the euler angles ( x and z are swapped ).\n",
        "def rotationMatrixToEulerAngles(R):\n",
        "    assert(isRotationMatrix(R))\n",
        "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
        "    singular = sy < 1e-6\n",
        "    if not singular:\n",
        "        x = math.atan2(R[2, 1], R[2, 2])\n",
        "        y = math.atan2(-R[2, 0], sy)\n",
        "        z = math.atan2(R[1, 0], R[0, 0])\n",
        "    else:\n",
        "        x = math.atan2(-R[1, 2], R[1, 1])\n",
        "        y = math.atan2(-R[2, 0], sy)\n",
        "        z = 0\n",
        "    return np.array([x, y, z])\n",
        "\n",
        "def getHeadTiltAndCoords(size, image_points, frame_height):\n",
        "    focal_length = size[1]\n",
        "    center = (size[1]/2, size[0]/2)\n",
        "    camera_matrix = np.array([[focal_length, 0, center[0]], [\n",
        "        0, focal_length, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "\n",
        "    # print \"Camera Matrix :\\n {0}\".format(camera_matrix)\n",
        "\n",
        "    dist_coeffs = np.zeros((4, 1))  # Assuming no lens distortion\n",
        "    (_, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points,\n",
        "                                                                  camera_matrix, dist_coeffs, \n",
        "                                                                  flags = cv2.SOLVEPNP_ITERATIVE)  # flags=cv2.CV_ITERATIVE)\n",
        "\n",
        "    # print \"Rotation Vector:\\n {0}\".format(rotation_vector)\n",
        "    # print \"Translation Vector:\\n {0}\".format(translation_vector)\n",
        "    # Project a 3D point (0, 0 , 1000.0) onto the image plane\n",
        "    # We use this to draw a line sticking out of the nose_end_point2D\n",
        "    (nose_end_point2D, _) = cv2.projectPoints(np.array(\n",
        "        [(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
        "\n",
        "    #get rotation matrix from the rotation vector\n",
        "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
        "\n",
        "    #calculate head tilt angle in degrees\n",
        "    head_tilt_degree = abs(\n",
        "        [-180] - np.rad2deg([rotationMatrixToEulerAngles(rotation_matrix)[0]]))\n",
        "\n",
        "    #calculate starting and ending points for the two lines for illustration\n",
        "    starting_point = (int(image_points[0][0]), int(image_points[0][1]))\n",
        "    ending_point = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
        "\n",
        "    ending_point_alternate = (ending_point[0], frame_height // 2)\n",
        "\n",
        "    return head_tilt_degree, starting_point, ending_point, ending_point_alternate"
      ],
      "metadata": {
        "id": "xnXMpXGnzR1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ1RpNrsHAwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "369bd55b-5424-45b1-92fa-a9dfb8607a03"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\t#capturing the video\n",
        "sVideoName = sDir + \"/videos_i8_crop/1-1.mp4\"\n",
        "cap=cv2.VideoCapture(sVideoName)\n",
        "oFeatureDict = init()\n",
        "\n",
        "landmarkPoints = []\n",
        "j = 0\n",
        "iFlagBlink = 0\n",
        "iFlagEyelid = 0\n",
        "oStartTimeBlink = 0\n",
        "frame_counter = 0\n",
        "while(cap.isOpened()):\n",
        "\t\t#returns the frame\n",
        "\tret, frame = cap.read()\n",
        "\tif ret != True:\n",
        "\t\tbreak\n",
        "\t\n",
        "\n",
        "\tframe = imutils.resize(frame, width=1024, height=576)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\tsize = gray.shape\n",
        "\n",
        "\t# detect faces in the grayscale frame\n",
        "\trects = detector(gray, 0)\n",
        "\n",
        "\t# check to see if a face was detected, and if so, draw the total\n",
        "\t# number of faces on the frame\n",
        "\tif len(rects) > 0:\n",
        "\t\t\ttext = \"{} face(s) found\".format(len(rects))\n",
        "\t\t\tcv2.putText(frame, text, (10, 20),\n",
        "\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "\t# loop over the face detections\n",
        "\tfor rect in rects:\n",
        "\t\t\t# compute the bounding box of the face and draw it on the\n",
        "\t\t\t# frame\n",
        "\t\t\t(bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
        "\t\t\tcv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1)\n",
        "\t\t\t# determine the facial landmarks for the face region, then\n",
        "\t\t\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
        "\t\t\t# array\n",
        "\t\t\tshape = predictor(gray, rect)\n",
        "\t\t\tshape = face_utils.shape_to_np(shape)\n",
        "\n",
        "\n",
        "\t# coordinates = [] for training purpose \n",
        "\t# landmarkPoints = oFeatureDict['data'][j].split()\n",
        "\t# for i in range(0,136,2):\n",
        "\t# \t\tfX = float(landmarkPoints[i])\n",
        "\t# \t\tfY = float(landmarkPoints[i + 1])\n",
        "\t# \t\tcoordinates.append((fX,fY))\n",
        "\t# leftEye = coordinates[lStart:lEnd]\n",
        "\t# rightEye = coordinates[rStart:rEnd]\n",
        "\t\n",
        "\tleftEye = shape[lStart:lEnd]\n",
        "\trightEye = shape[rStart:rEnd]\n",
        "\tmouth_shape = shape[omouth:emouth]\n",
        "\n",
        "\tmouth = mouth_aspect_ratio(mouth_shape)\n",
        "\tleftEAR = eye_aspect_ratio(leftEye)\n",
        "\trightEAR = eye_aspect_ratio(rightEye)\n",
        "\t\n",
        "\t\n",
        "\n",
        "\t#average the eye aspect ratio together for both eyes\n",
        "\tear = (leftEAR + rightEAR) / 2.0\n",
        "\t\n",
        "\n",
        "\t\n",
        "\t#check the blink count\t\t\n",
        "\tif iFlagBlink == 0 and ear < EYE_AR_THRESH:\t\n",
        "\t\tiFlagBlink = 1\t\t\n",
        "\t\toStartTimeBlink = oFeatureDict['time'][j]\t\t\n",
        "\t\t\n",
        "\tif iFlagBlink==1 and ear > EYE_AR_THRESH:\n",
        "\t\tiFlagBlink=0\n",
        "\t\tend_time = oFeatureDict['time'][j]\n",
        "\t\t\n",
        "\t\ttime_diff = time_difference( str(oStartTimeBlink), str(end_time)) \n",
        "\t\t\n",
        "\t\toFeatureDict['start_timestamp'].append(oStartTimeBlink)\n",
        "\t\toFeatureDict['blink_duration'].append(time_diff)\n",
        "\t\t\n",
        "\t#calculating the average blink duration and blink frequency\n",
        "\toFeatureDict['start_timestamp'], oFeatureDict['blink_duration'] = one_min(oFeatureDict['start_timestamp'],oFeatureDict['blink_duration'])\n",
        "\t\n",
        "\tif(len(oFeatureDict['blink_duration'])>0):\n",
        "\t\tavgblinkdur = sum(oFeatureDict['blink_duration'])/len(oFeatureDict['blink_duration'])\n",
        "\t\toFeatureDict['avgBlinkDurationBuffer'].append(avgblinkdur)\n",
        "\t\t# print ('avgblinkdur', avgblinkdur)\n",
        "\t\t#print oFeatureDict['avgBlinkDurationBuffer']\n",
        "\telse:\n",
        "\t\tavgblinkdur = 0\n",
        "\t\toFeatureDict['avgBlinkDurationBuffer'].append(avgblinkdur)\n",
        "\t\t# print ('avgblinkdur', avgblinkdur)\n",
        "\n",
        "\t#blink frequency\n",
        "\tavgBlinkFreq = len(blink_duration)\n",
        "\toFeatureDict['avgBlinkFreqBuffer'].append(avgBlinkFreq)\n",
        "\t# print ('blinkfreq', avgBlinkFreq)\n",
        "\t#print oFeatureDict['avgBlinkFreqBuffer']\n",
        "\n",
        "\t\n",
        "\t#calculating the Perclos value\n",
        "\tif ear < 0.3:\n",
        "\t\tc_counter = 1\n",
        "\t\toFeatureDict['perclos'].append(c_counter)\n",
        "\telse: \n",
        "\t\to_counter = 0\n",
        "\t\toFeatureDict['perclos'].append(o_counter)\n",
        "\n",
        "\toFeatureDict['timestampEveryMin'].append(oFeatureDict['time'][j])\n",
        "\t\t\n",
        "\toFeatureDict['timestampEveryMin'], oFeatureDict['perclos'] = one_min(oFeatureDict['timestampEveryMin'], oFeatureDict['perclos'])\n",
        "\n",
        "\tif (len(oFeatureDict['perclos'])>0):\n",
        "\t\tavg_perclos = sum(oFeatureDict['perclos'])/float(len(oFeatureDict['perclos']))\n",
        "\t\toFeatureDict['average_perclos'].append(avg_perclos)\n",
        "\t\t# print ('avg perclos', avg_perclos)\n",
        "\t\t#print 'average perclos', oFeatureDict['average_perclos']\n",
        "\telse:\n",
        "\t\tavg_perclos = 0\n",
        "\t\toFeatureDict['average_perclos'].append(avg_perclos)\n",
        "\t\t# print ('avg perclos', avg_perclos)\n",
        "\n",
        "\n",
        "\t#getting the kss values\n",
        "\tKSS = oFeatureDict['kss'][0].rstrip('\\n')\n",
        "\t# print (KSS)\n",
        "\toFeatureDict['kss_val'].append(KSS)\n",
        "\t#print oFeatureDict['kss_val']\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t#displaying the average blink duration        \n",
        "\tcv2.putText(frame, 'avgBlinkDur'+str(oFeatureDict['avgBlinkDurationBuffer'][j]), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)     \n",
        "\t\t\t\t\t\t\t#displaying levels of drowsiness\n",
        "\tcv2.putText(frame, 'avgperclos'+str(oFeatureDict['average_perclos'][j]), (100, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "\t#displaying the blink freq\n",
        "\tcv2.putText(frame, 'avgblinkfreq'+str(oFeatureDict['avgBlinkFreqBuffer'][j]), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\t\n",
        "\tcv2.putText(frame, 'frame number'+str(j), (30, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "\t\n",
        "\t# compute the convex hull for the mouth, then\n",
        "\t# visualize the mouth\n",
        "\n",
        "\t# Draw text if mouth is open\n",
        "\tmouth = shape[omouth:emouth]\n",
        "\n",
        "\tmouthMAR = mouth_aspect_ratio(mouth)\n",
        "\tmar = mouthMAR\n",
        "\t# compute the convex hull for the mouth, then\n",
        "\t# visualize the mouth\n",
        "\tmouthHull = cv2.convexHull(mouth)\n",
        " \n",
        "\n",
        "\tcv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
        "\tcv2.putText(frame, \"MAR: {:.2f}\".format(mar), (650, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\toFeatureDict[\"MAR\"].append(round(mar,2))\n",
        "\n",
        "\t# Draw text if mouth is open\n",
        "\tif mar > MOUTH_AR_THRESH:\n",
        "\t\t\toFeatureDict[\"Yawning\"].append(1) \n",
        "\t\t\tcv2.putText(frame, \"Yawning!\", (20, 80),\n",
        "\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "\telse:\n",
        "\t\t\toFeatureDict[\"Yawning\"].append(0)\n",
        "\t\t\tcv2.putText(frame, \"NOT Yawning!\", (20, 80),\n",
        "\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
        "\t#showing the image\n",
        "\t#cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
        "\t# cv2.imshow('frame', frame)\n",
        "\tfor (i, (x, y)) in enumerate(shape):\n",
        "\n",
        "\t\tif i == 33:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[0] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telif i == 8:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[1] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telif i == 36:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[2] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telif i == 45:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[3] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telif i == 48:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[4] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telif i == 54:\n",
        "\t\t\t\t# something to our key landmarks\n",
        "\t\t\t\t# save to our new key point list\n",
        "\t\t\t\t# i.e. keypoints = [(i,(x,y))]\n",
        "\t\t\t\timage_points[5] = np.array([x, y], dtype='double')\n",
        "\t\t\t\t# write on frame in Green\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
        "\t\telse:\n",
        "\t\t\t\t# everything to all other landmarks\n",
        "\t\t\t\t# write on frame in Red\n",
        "\t\t\t\tcv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
        "\t\t\t\tcv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
        "\t\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
        "\n",
        "\t\t\t#Draw the determinant image points onto the person's face\n",
        "\tfor p in image_points:\n",
        "\t\t\tcv2.circle(frame, (int(p[0]), int(p[1])), 3, (0, 0, 255), -1)\n",
        "\n",
        "\t(head_tilt_degree, start_point, end_point, \n",
        "\t\t\tend_point_alt) = getHeadTiltAndCoords(size, image_points, frame_height)\n",
        "\n",
        "\tcv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
        "\tcv2.line(frame, start_point, end_point_alt, (0, 0, 255), 2)\n",
        "\toFeatureDict['headpos1'].append(head_tilt_degree[0])\n",
        "\n",
        "\tif head_tilt_degree:\n",
        "\t\t\tcv2.putText(frame, 'Head Tilt Degree: ' + str(head_tilt_degree[0]), (170, 20),\n",
        "\t\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\tfrom google.colab.patches import cv2_imshow \n",
        "\tcv2_imshow(frame)\n",
        "\n",
        "\t# print ('j', j)\n",
        "\t#print 'ear', ear\n",
        "\t\n",
        "\tif cv2.waitKey(0) & 0xff==ord('q'): \n",
        "\t\tbreak\n",
        "\t\n",
        "\tj = j + 1\n",
        "\n",
        "\n",
        "#releasing the cap\n",
        "cap.release()\n",
        "cv2.destroyAllWindows() \n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writing the csv files for avg blink duration, blink frequency and perclos\n",
        "with open('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/1-1.csv', 'w') as f2:\n",
        "\tspamwriter = csv.writer(f2, delimiter=',',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tquotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "\tdata = list(zip(oFeatureDict['avgBlinkDurationBuffer'], oFeatureDict['avgBlinkFreqBuffer'], oFeatureDict['average_perclos'], oFeatureDict[\"MAR\"], oFeatureDict[\"Yawning\"], oFeatureDict[\"headpos1\"], oFeatureDict['kss_val']))\n",
        "\tfor row in data:\n",
        "\t\t\trow = list(row)\n",
        "\t\t\tspamwriter.writerow(row)\t"
      ],
      "metadata": {
        "id": "yvcB0iq6XzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It48gv8OHAzp"
      },
      "outputs": [],
      "source": [
        "oFeatureDict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGI7P421HA2Y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZFDPPPMHA5O"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhKUkUvDHA9M"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iapw4ILtHBAc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln5PF3yrHBGm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqzndDnrHBK_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "BlinkDet (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}