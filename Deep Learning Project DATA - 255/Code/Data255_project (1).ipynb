{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihyrihQBqMT5",
        "outputId": "d290f63d-a2be-4789-b08d-9fe7e7b024af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive #using google drive for storage\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhnd63XQwH85"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "#from sklearn.datasets.samples_generator import make_blobs\n",
        "#from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import csv\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization \n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.utils import plot_model\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "\n",
        "FeatureVector = []\n",
        "Y_train = []\n",
        "Y_val = []\n",
        "YTest = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxOe9fzYwIIq",
        "outputId": "efceca0d-226c-4774-fb41-c96dcc60daf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/1-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/1-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/1-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/2-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/2-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/2-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/3-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/3-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/3-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/4-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/4-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/4-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/5-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/5-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/5-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/6-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/6-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/6-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/7-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/7-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/8-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/8-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/8-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/9-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/9-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/10-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/10-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/11-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/11-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/11-3.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/12-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/13-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/13-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/14-1.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/14-2.csv\n",
            "gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new/14-3.csv\n"
          ]
        }
      ],
      "source": [
        "#loading the model\n",
        "#model = load_model(\"trained_models/DrowDet_model(output4).hdf5\")\n",
        "\n",
        "\n",
        "basename = os.path.basename(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY\") \n",
        "dir= os.path.dirname('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY')\n",
        "\n",
        "\n",
        "for (root,dirs,files) in os.walk('gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/csvfile_new', topdown=True):\n",
        "    for x in files:\n",
        "        files=os.path.join(root, x)\n",
        "        print(files)\n",
        "\n",
        "        with open(files, 'r') as f:\n",
        "          for sline in f:\n",
        "            sline = sline.rstrip('\\n')\n",
        "            data = sline.split(',')\n",
        "            csvfile = []\n",
        "            for i in range(0,7):\n",
        "                sdata = float(data[i])\n",
        "                csvfile.append(sdata)\n",
        "            FeatureVector.append(csvfile)\n",
        "\n",
        "sFeatureVector = np.array(FeatureVector)\n",
        "\n",
        "#shuffling the data\n",
        "random.Random(4).shuffle(sFeatureVector)\n",
        "\n",
        "#splitting the training and testing data\n",
        "splitTrainStart = 0\n",
        "splitTrainEnd = int(0.7*len(sFeatureVector))\n",
        "splitValStart = int(splitTrainEnd)\n",
        "splitValEnd = int(splitValStart + 0.2*len(sFeatureVector))\n",
        "splitTestStart = int(splitValEnd)\n",
        "splitTestEnd = int(splitTestStart + 0.1*len(sFeatureVector))\n",
        "\n",
        "\n",
        "#dataset\n",
        "Xtrain = sFeatureVector[splitTrainStart:splitTrainEnd, 0:6]\n",
        "Ytrain = sFeatureVector[splitTrainStart:splitTrainEnd, -1]\n",
        "Xval = sFeatureVector[splitValStart:splitValEnd, 0:6]\n",
        "Yval = sFeatureVector[splitValStart:splitValEnd, -1]\n",
        "X_Test = sFeatureVector[splitTestStart:splitTestEnd, 0:6]\n",
        "Y_Test = sFeatureVector[splitTestStart:splitTestEnd, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSS8mwHJzVXQ",
        "outputId": "9cd16fbf-6908-4d8f-bb8e-41edfd52aa3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105101, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sFeatureVector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XawPY-qxwrlK",
        "outputId": "50f3384b-bc5b-4006-ceee-46d28a9f9977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.       ,  0.       ,  0.       ,  0.3      ,  0.       ,\n",
              "       10.2447297])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Xtrain[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "flRQbeaQwIN8",
        "outputId": "64925c6d-593b-4bc2-8a9e-9e4c0a813e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#dumping the data\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowTrainRevised.pickle\",\"rb\")\\nXtrain=pickle.load(pickle_off)\\n\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowTrainRevised.pickle\",\"rb\")\\nYtrain=pickle.load(pickle_off)\\n\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowValRevised.pickle\",\"rb\")\\nXval=pickle.load(pickle_off)\\n\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowValRevised.pickle\",\"rb\")\\nYval=pickle.load(pickle_off)\\n\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowTestRevised.pickle\",\"rb\")\\nX_Test=pickle.load(pickle_off)\\n\\npickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowTestRevised.pickle\",\"rb\")\\nY_Test=pickle.load(pickle_off)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "#dumping the data\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowTrainRevised.pickle\",\"rb\")\n",
        "Xtrain=pickle.load(pickle_off)\n",
        "\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowTrainRevised.pickle\",\"rb\")\n",
        "Ytrain=pickle.load(pickle_off)\n",
        "\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowValRevised.pickle\",\"rb\")\n",
        "Xval=pickle.load(pickle_off)\n",
        "\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowValRevised.pickle\",\"rb\")\n",
        "Yval=pickle.load(pickle_off)\n",
        "\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/xDrowTestRevised.pickle\",\"rb\")\n",
        "X_Test=pickle.load(pickle_off)\n",
        "\n",
        "pickle_off=open(\"gdrive/My Drive/DROZY.zip (Unzipped Files)/DROZY/DrowDetSys/yDrowTestRevised.pickle\",\"rb\")\n",
        "Y_Test=pickle.load(pickle_off)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myset = set(Ytrain)\n",
        "print(myset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc3sQvvrZfZq",
        "outputId": "f8c9f1ad-48f2-46bc-e6af-6621e9958a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2.0, 3.0, 4.0, 6.0, 7.0, 8.0, 9.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYmRP_8JwITS"
      },
      "outputs": [],
      "source": [
        "#finding the max from the data columnwise\n",
        "max1 = Xtrain[:,0].max()\n",
        "max2 = Xtrain[:,1].max()\n",
        "max3 = Xtrain[:,2].max()\n",
        "max4 = Xtrain[:,3].max()\n",
        "max5 = Xtrain[:,4].max()\n",
        "max6 = Xtrain[:,5].max()\n",
        "\n",
        "#scaling the training data\n",
        "NormTrain1 = Xtrain[:,0]/max1\n",
        "NormTrain2 = Xtrain[:,1]/max2\n",
        "NormTrain3 = Xtrain[:,2]/max3\n",
        "NormTrain4 = Xtrain[:,3]/max4\n",
        "NormTrain5 = Xtrain[:,4]/max5\n",
        "NormTrain6 = Xtrain[:,5]/max6\n",
        "\n",
        "\n",
        "#scaling the validating data\n",
        "NormVal1 = Xval[:,0]/max1\n",
        "NormVal2 = Xval[:,1]/max2\n",
        "NormVal3 = Xval[:,2]/max3\n",
        "NormVal4 = Xval[:,3]/max4\n",
        "NormVal5 = Xval[:,4]/max5\n",
        "NormVal6 = Xval[:,5]/max6\n",
        "\n",
        "#scaling the testing data\n",
        "NormTest1 = X_Test[:,0]/max1\n",
        "NormTest2 = X_Test[:,1]/max2\n",
        "NormTest3 = X_Test[:,2]/max3\n",
        "NormTest4 = X_Test[:,3]/max4\n",
        "NormTest5 = X_Test[:,4]/max5\n",
        "NormTest6 = X_Test[:,5]/max6\n",
        "\n",
        "\n",
        "#concatenating arrays to prepare training, validating and testing data\n",
        "Xtrain = np.vstack((NormTrain1, NormTrain2, NormTrain3, NormTrain4, NormTrain5, NormTrain6))\n",
        "Xtrain = Xtrain.T\n",
        "Xval = np.vstack((NormVal1, NormVal2, NormVal3, NormVal4, NormVal5, NormVal6)) \n",
        "Xval = Xval.T\n",
        "X_Test = np.vstack((NormTest1, NormTest2, NormTest3,NormTest4, NormTest5, NormTest6))\n",
        "X_Test = X_Test.T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeruCg75ZIlS",
        "outputId": "3dd1de65-b9cb-4115-8cd9-5824c8eba829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.34883721, 0.        ,\n",
              "        0.02845763],\n",
              "       [0.        , 0.        , 0.        , 0.3255814 , 0.        ,\n",
              "        0.02898833],\n",
              "       [0.        , 0.        , 0.        , 0.34883721, 0.        ,\n",
              "        0.0289893 ],\n",
              "       ...,\n",
              "       [0.22048239, 0.89705882, 0.26222222, 0.44186047, 0.        ,\n",
              "        0.00916061],\n",
              "       [0.07111268, 0.42647059, 0.05674847, 0.41860465, 0.        ,\n",
              "        0.03887736],\n",
              "       [0.04527133, 0.07352941, 0.01010101, 0.34883721, 0.        ,\n",
              "        0.02858552]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JBugeJ-zDgT",
        "outputId": "e9636599-6dc0-40a2-85cf-2f8e7af865e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73570, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "Xtrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0P3heNcwIXE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#relabeling the levels\n",
        "for i in range(len(Ytrain)):\n",
        "\tif Ytrain[i]==2 or Ytrain[i] ==3 or Ytrain[i]== 4:\n",
        "\t\tlabel = 1\n",
        "\t\tY_train.append(label)\n",
        "\telif Ytrain[i]==6 or Ytrain[i]== 5:\n",
        "\t\tlabel = 2\n",
        "\t\tY_train.append(label)\n",
        "\telse:\n",
        "\t\tlabel = 3\n",
        "\t\tY_train.append(label)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(Yval)):\n",
        "\tif Yval[i]==2 or Yval[i]==3 or Yval[i]== 4:\n",
        "\t\tlabel = 1\n",
        "\t\tY_val.append(label)\n",
        "\telif Yval[i]==6 or Yval[i]== 5:\n",
        "\t\tlabel = 2\n",
        "\t\tY_val.append(label)\n",
        "\telse:\n",
        "\t\tlabel = 3\n",
        "\t\tY_val.append(label)\n",
        "\n",
        "\n",
        "for i in range(len(Y_Test)):\n",
        "\tif Y_Test[i]==2 or Y_Test[i]==3 or Y_Test[i]==4:\n",
        "\t\tlabel = 1\n",
        "\t\tYTest.append(label)\n",
        "\telif Y_Test[i]==5 or Y_Test[i]==6:\n",
        "\t\tlabel = 2\n",
        "\t\tYTest.append(label)\n",
        "\telse:\n",
        "\t\tlabel = 3\n",
        "\t\tYTest.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwOM9ezBhjpj"
      },
      "outputs": [],
      "source": [
        "# Ytrain = [cleaning(x) for x in Ytrain]\n",
        "# Y_Test = [cleaning(x) for x in Ytrain]\n",
        "# Yval = [cleaning(x) for x in Ytrain]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMdskIXZ0psJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "Ytrain = np.array(Y_train)\n",
        "Yval = np.array(Y_val)\n",
        "Y_Test = np.array(YTest)\t\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B_oxgdroZ_u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-LMCIEog_k6",
        "outputId": "1174a5de-7f9c-4cdf-89ee-d2e4b00ea183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3}\n"
          ]
        }
      ],
      "source": [
        "myset = set(Ytrain)\n",
        "print(myset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain = np_utils.to_categorical(Ytrain)\n",
        "Yval = np_utils.to_categorical(Yval)\n",
        "Y_Test = np_utils.to_categorical(Y_Test)"
      ],
      "metadata": {
        "id": "BAdPBxZMXtrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuFx4vHfYohM",
        "outputId": "bb187439-23d4-414d-c44b-4c5550060ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxPwWZ8lwIac",
        "outputId": "73f6f2fe-4d4b-4679-f3bf-d7a976998889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 2s 3ms/step - loss: 0.8878 - accuracy: 0.6584 - val_loss: 0.9569 - val_accuracy: 0.6192\n",
            "Epoch 2/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.6834 - accuracy: 0.7215 - val_loss: 0.9776 - val_accuracy: 0.6384\n",
            "Epoch 3/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.6085 - accuracy: 0.7439 - val_loss: 0.9194 - val_accuracy: 0.6675\n",
            "Epoch 4/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.5714 - accuracy: 0.7546 - val_loss: 0.8989 - val_accuracy: 0.6770\n",
            "Epoch 5/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.5467 - accuracy: 0.7685 - val_loss: 0.8939 - val_accuracy: 0.6799\n",
            "Epoch 6/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.5144 - accuracy: 0.7902 - val_loss: 0.8658 - val_accuracy: 0.6987\n",
            "Epoch 7/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8078 - val_loss: 0.8364 - val_accuracy: 0.7174\n",
            "Epoch 8/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8160 - val_loss: 0.8045 - val_accuracy: 0.7206\n",
            "Epoch 9/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4408 - accuracy: 0.8279 - val_loss: 0.8571 - val_accuracy: 0.7069\n",
            "Epoch 10/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4251 - accuracy: 0.8354 - val_loss: 0.7926 - val_accuracy: 0.7222\n",
            "Epoch 11/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4067 - accuracy: 0.8448 - val_loss: 0.8144 - val_accuracy: 0.7321\n",
            "Epoch 12/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8530 - val_loss: 0.8223 - val_accuracy: 0.7352\n",
            "Epoch 13/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.8577 - val_loss: 0.7654 - val_accuracy: 0.7402\n",
            "Epoch 14/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8642 - val_loss: 0.8301 - val_accuracy: 0.7449\n",
            "Epoch 15/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3468 - accuracy: 0.8676 - val_loss: 0.9038 - val_accuracy: 0.7389\n",
            "Epoch 16/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8701 - val_loss: 0.7895 - val_accuracy: 0.7574\n",
            "Epoch 17/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3226 - accuracy: 0.8753 - val_loss: 0.7816 - val_accuracy: 0.7544\n",
            "Epoch 18/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8783 - val_loss: 0.8144 - val_accuracy: 0.7568\n",
            "Epoch 19/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.8808 - val_loss: 0.7667 - val_accuracy: 0.7555\n",
            "Epoch 20/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.8846 - val_loss: 0.7517 - val_accuracy: 0.7657\n",
            "Epoch 21/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.8859 - val_loss: 0.7730 - val_accuracy: 0.7647\n",
            "Epoch 22/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.8896 - val_loss: 0.7684 - val_accuracy: 0.7685\n",
            "Epoch 23/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8932 - val_loss: 0.8551 - val_accuracy: 0.7549\n",
            "Epoch 24/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8971 - val_loss: 0.7667 - val_accuracy: 0.7791\n",
            "Epoch 25/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2556 - accuracy: 0.8989 - val_loss: 0.7720 - val_accuracy: 0.7759\n",
            "Epoch 26/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2490 - accuracy: 0.9017 - val_loss: 0.7616 - val_accuracy: 0.7860\n",
            "Epoch 27/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.9069 - val_loss: 0.8293 - val_accuracy: 0.7757\n",
            "Epoch 28/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2348 - accuracy: 0.9101 - val_loss: 0.7451 - val_accuracy: 0.7963\n",
            "Epoch 29/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9128 - val_loss: 0.7886 - val_accuracy: 0.8007\n",
            "Epoch 30/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2193 - accuracy: 0.9173 - val_loss: 0.7483 - val_accuracy: 0.8065\n",
            "Epoch 31/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2188 - accuracy: 0.9177 - val_loss: 0.7889 - val_accuracy: 0.8130\n",
            "Epoch 32/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2057 - accuracy: 0.9255 - val_loss: 0.7448 - val_accuracy: 0.8089\n",
            "Epoch 33/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.2061 - accuracy: 0.9247 - val_loss: 0.8041 - val_accuracy: 0.8182\n",
            "Epoch 34/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9304 - val_loss: 0.8018 - val_accuracy: 0.8238\n",
            "Epoch 35/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9339 - val_loss: 0.7607 - val_accuracy: 0.8268\n",
            "Epoch 36/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1871 - accuracy: 0.9341 - val_loss: 0.8240 - val_accuracy: 0.8298\n",
            "Epoch 37/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9385 - val_loss: 0.7686 - val_accuracy: 0.8300\n",
            "Epoch 38/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9388 - val_loss: 0.7939 - val_accuracy: 0.8378\n",
            "Epoch 39/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1667 - accuracy: 0.9432 - val_loss: 0.7816 - val_accuracy: 0.8480\n",
            "Epoch 40/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1629 - accuracy: 0.9448 - val_loss: 0.8376 - val_accuracy: 0.8372\n",
            "Epoch 41/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9448 - val_loss: 0.8288 - val_accuracy: 0.8457\n",
            "Epoch 42/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9477 - val_loss: 0.7943 - val_accuracy: 0.8446\n",
            "Epoch 43/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9467 - val_loss: 0.7808 - val_accuracy: 0.8517\n",
            "Epoch 44/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9504 - val_loss: 0.7838 - val_accuracy: 0.8578\n",
            "Epoch 45/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1443 - accuracy: 0.9511 - val_loss: 0.7955 - val_accuracy: 0.8572\n",
            "Epoch 46/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.8120 - val_accuracy: 0.8524\n",
            "Epoch 47/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9538 - val_loss: 0.8209 - val_accuracy: 0.8557\n",
            "Epoch 48/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9531 - val_loss: 0.8337 - val_accuracy: 0.8535\n",
            "Epoch 49/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1323 - accuracy: 0.9549 - val_loss: 0.8402 - val_accuracy: 0.8605\n",
            "Epoch 50/50\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.1315 - accuracy: 0.9548 - val_loss: 0.8361 - val_accuracy: 0.8674\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#one h0t encode outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#designing the model\n",
        "model=Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(32, input_dim=6, activation='relu'))\n",
        "model.add(Dense(16, input_dim=6, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax', use_bias=False))\n",
        "\n",
        "#compile the model\n",
        "#adam = keras.optimizers.Adam(lr=0.01)\n",
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#fit the model\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath=\"trained_models/DrowDet_model(output4).hdf5\", period=1)\n",
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./scalar', histogram_freq=0, write_graph=True, write_images=True)\n",
        "history=model.fit(Xtrain, Ytrain, epochs=50, batch_size=256, callbacks=[checkpoint, tbCallBack], validation_data=(Xval,Yval))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJfz2IS2TNJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "79a0acb5-9689-4f4b-8078-106272e391f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 2.0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Training Accuracy vs Validation Accuracy ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.ylim([0,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31_UGhyXwIfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d6c07a-0f74-4111-b22e-4d0fd3cade7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing Confusion Matrix :\n",
            "[[4465   97  703]\n",
            " [ 492  973  139]\n",
            " [1032   75 2534]]\n",
            "testing Accuracy Score : 0.7585156993339677\n",
            "testing Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.85      0.79      5265\n",
            "           2       0.85      0.61      0.71      1604\n",
            "           3       0.75      0.70      0.72      3641\n",
            "\n",
            "    accuracy                           0.76     10510\n",
            "   macro avg       0.78      0.72      0.74     10510\n",
            "weighted avg       0.76      0.76      0.76     10510\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#calculating the testing score of the data\n",
        "predictions=model.predict(X_Test)\n",
        "prob3=predictions.argmax(axis=1)\n",
        "y_true=Y_Test.argmax(axis=1)\n",
        "y_prediction=prob3\n",
        "\n",
        "#confusion matrix\n",
        "results = confusion_matrix(y_true, y_prediction) \n",
        "print('testing Confusion Matrix :')\n",
        "print(results) \n",
        "print('testing Accuracy Score :',accuracy_score(y_true, y_prediction)) \n",
        "print('testing Report : ')\n",
        "print(classification_report(y_true, y_prediction)) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfEsooFWwIi1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "087dd62a-01ba-4bcd-e5fa-35e29ba58368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288/288 [==============================] - 1s 3ms/step - loss: 0.9180 - accuracy: 0.6412 - val_loss: 0.9160 - val_accuracy: 0.5706\n",
            "Epoch 2/100\n",
            "288/288 [==============================] - 1s 2ms/step - loss: 0.7486 - accuracy: 0.6928 - val_loss: 0.9039 - val_accuracy: 0.6236\n",
            "Epoch 3/100\n",
            "288/288 [==============================] - 1s 2ms/step - loss: 0.7042 - accuracy: 0.7095 - val_loss: 0.8877 - val_accuracy: 0.6403\n",
            "Epoch 4/100\n",
            "288/288 [==============================] - 1s 2ms/step - loss: 0.6729 - accuracy: 0.7232 - val_loss: 0.8807 - val_accuracy: 0.6527\n",
            "Epoch 5/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.6403 - accuracy: 0.7356 - val_loss: 0.8839 - val_accuracy: 0.6459\n",
            "Epoch 6/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.6096 - accuracy: 0.7452 - val_loss: 0.8504 - val_accuracy: 0.6651\n",
            "Epoch 7/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.5725 - accuracy: 0.7582 - val_loss: 0.8630 - val_accuracy: 0.6678\n",
            "Epoch 8/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7758 - val_loss: 0.8225 - val_accuracy: 0.6900\n",
            "Epoch 9/100\n",
            "288/288 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.7999 - val_loss: 0.8518 - val_accuracy: 0.6940\n",
            "Epoch 10/100\n",
            "288/288 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.8146 - val_loss: 0.8283 - val_accuracy: 0.7082\n",
            "Epoch 11/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.8250 - val_loss: 0.8310 - val_accuracy: 0.7034\n",
            "Epoch 12/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.8304 - val_loss: 0.8440 - val_accuracy: 0.7128\n",
            "Epoch 13/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4455 - accuracy: 0.8352 - val_loss: 0.8297 - val_accuracy: 0.7137\n",
            "Epoch 14/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8392 - val_loss: 0.8232 - val_accuracy: 0.7178\n",
            "Epoch 15/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4287 - accuracy: 0.8409 - val_loss: 0.8404 - val_accuracy: 0.7165\n",
            "Epoch 16/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4217 - accuracy: 0.8443 - val_loss: 0.8310 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4164 - accuracy: 0.8457 - val_loss: 0.8453 - val_accuracy: 0.7256\n",
            "Epoch 18/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.8480 - val_loss: 0.8708 - val_accuracy: 0.7337\n",
            "Epoch 19/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4091 - accuracy: 0.8494 - val_loss: 0.8622 - val_accuracy: 0.7316\n",
            "Epoch 20/100\n",
            "288/288 [==============================] - 1s 3ms/step - loss: 0.4034 - accuracy: 0.8508 - val_loss: 0.8611 - val_accuracy: 0.7288\n",
            "Epoch 21/100\n",
            "191/288 [==================>...........] - ETA: 0s - loss: 0.3982 - accuracy: 0.8537"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2dd20558d657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trained_models/DrowDet_model(output4).hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtbCallBack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./scalar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#designing the model\n",
        "model=Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(4, activation='softmax', use_bias=False))\n",
        "\n",
        "#compile the model\n",
        "#adam = keras.optimizers.Adam(lr=0.01)\n",
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#fit the model\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath=\"trained_models/DrowDet_model(output4).hdf5\", period=1)\n",
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./scalar', histogram_freq=0, write_graph=True, write_images=True)\n",
        "history=model.fit(Xtrain, Ytrain, epochs=100, batch_size=256, callbacks=[checkpoint, tbCallBack], validation_data=(Xval,Yval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZayeT1aOlBM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Training Accuracy vs Validation Accuracy ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.ylim([0,2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the testing score of the data\n",
        "predictions=model.predict(X_Test)\n",
        "prob3=predictions.argmax(axis=1)\n",
        "y_true=Y_Test.argmax(axis=1)\n",
        "y_prediction=prob3\n",
        "\n",
        "#confusion matrix\n",
        "results = confusion_matrix(y_true, y_prediction) \n",
        "print('testing Confusion Matrix :')\n",
        "print(results) \n",
        "print('testing Accuracy Score :',accuracy_score(y_true, y_prediction)) \n",
        "print('testing Report : ')\n",
        "print(classification_report(y_true, y_prediction)) "
      ],
      "metadata": {
        "id": "v035tvtxcWUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTWlfjTAqBvx"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "#designing the model\n",
        "model=Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.001))\n",
        "model.add(Dense(4, activation='softmax', use_bias=False))\n",
        "\n",
        "#compile the model\n",
        "#adam = keras.optimizers.Adam(lr=0.01)\n",
        "adam = keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#fit the model\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath=\"trained_models/DrowDet_model(output4).hdf5\", period=1)\n",
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./scalar', histogram_freq=0, write_graph=True, write_images=True)\n",
        "history=model.fit(Xtrain, Ytrain, epochs=50, batch_size=256, callbacks=[checkpoint, tbCallBack], validation_data=(Xval,Yval))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxYOL5XWWQ6S"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Training Accuracy vs Validation Accuracy ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.ylim([0,2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iqD8TQUo519"
      },
      "outputs": [],
      "source": [
        "predictions=model.predict(X_Test)\n",
        "prob3=predictions.argmax(axis=1)\n",
        "y_true=Y_Test.argmax(axis=1)\n",
        "y_prediction=prob3\n",
        "\n",
        "#confusion matrix\n",
        "results = confusion_matrix(y_true, y_prediction) \n",
        "print('testing Confusion Matrix :')\n",
        "print(results) \n",
        "print('testing Accuracy Score :',accuracy_score(y_true, y_prediction)) \n",
        "print('testing Report : ')\n",
        "print(classification_report(y_true, y_prediction)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nw54r4t-pP7"
      },
      "outputs": [],
      "source": [
        "X_test_lstm = X_Test.reshape((X_Test.shape[0], 1, X_Test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lstm = Xtrain.reshape(Xtrain.shape[0], 1, Xtrain.shape[1])\n",
        "Xval_lstm = Xval.reshape(Xval.shape[0], 1, Xval.shape[1])"
      ],
      "metadata": {
        "id": "Y-srVgc5cqiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "12cAGhUldbsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "import numpy as np\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "#from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
        "    MaxPooling2D)\n",
        "from collections import deque\n",
        "import sys\n",
        "\n",
        "metrics = ['accuracy']\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(512, return_sequences=True,\n",
        "                       input_shape=(1, 6,),\n",
        "                       dropout=0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32, activation='relu')) #FC2\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))#FC3\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))#Output Layer\n",
        "#optimizer = Adam(lr=0.00005)\n",
        "adam = keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=metrics)\n",
        "model.fit(X_train_lstm, Ytrain, validation_data = (Xval_lstm,Yval), epochs=20, batch_size=  256)\n"
      ],
      "metadata": {
        "id": "N26Z5jCGwQxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(X_test_lstm)\n",
        "prob3=predictions.argmax(axis=1)\n",
        "y_true=Y_Test.argmax(axis=1)\n",
        "y_prediction=prob3\n",
        "\n",
        "#confusion matrix\n",
        "results = confusion_matrix(y_true, y_prediction) \n",
        "print('testing Confusion Matrix :')\n",
        "print(results) \n",
        "print('testing Accuracy Score :',accuracy_score(y_true, y_prediction)) \n",
        "print('testing Report : ')\n",
        "print(classification_report(y_true, y_prediction)) \n"
      ],
      "metadata": {
        "id": "fsDwxALDd_Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Training Accuracy vs Validation Accuracy ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.ylim([0,2])"
      ],
      "metadata": {
        "id": "uyjKTcjmewi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "#from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
        "    MaxPooling2D)\n",
        "from collections import deque\n",
        "import sys\n",
        "\n",
        "metrics = ['accuracy']\n",
        "model = Sequential()\n",
        "#model.add(Dense(1024, activation='sigmoid'))\n",
        "model.add(LSTM(512, return_sequences=True,\n",
        "                       input_shape=(1, 6,),\n",
        "                       dropout=0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "# Dense is fully connected layer. 16 hidden units\n",
        "# activation for lstm is basically sigmoid or tanh\n",
        "#model.add(Dense(216, activation='sigmoid')) #FC1\n",
        "model.add(Dense(32, activation='relu')) #FC2\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))#FC3\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))#Output Layer\n",
        "#optimizer = Adam(lr=0.00005)\n",
        "adam = keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=metrics)\n",
        "model.fit(X_train_lstm, Ytrain, validation_data = (Xval_lstm,Yval), epochs=50, batch_size=  256)\n"
      ],
      "metadata": {
        "id": "5Ztf56YmeM76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Training Accuracy vs Validation Accuracy ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.ylim([0,2])"
      ],
      "metadata": {
        "id": "tLW6NG9kezVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(X_test_lstm)\n",
        "prob3=predictions.argmax(axis=1)\n",
        "y_true=Y_Test.argmax(axis=1)\n",
        "y_prediction=prob3\n",
        "\n",
        "#confusion matrix\n",
        "results = confusion_matrix(y_true, y_prediction) \n",
        "print('testing Confusion Matrix :')\n",
        "print(results) \n",
        "print('testing Accuracy Score :',accuracy_score(y_true, y_prediction)) \n",
        "print('testing Report : ')\n",
        "print(classification_report(y_true, y_prediction)) "
      ],
      "metadata": {
        "id": "0E0RxSjMeRbV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Data255_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}